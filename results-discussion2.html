<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <title>My DEEP Learning webpage</title>
    <link href="styles/style.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css?family=Zilla+Slab:400,700|Open+Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.0.0/p5.min.js"></script>
  </head>
  <body>
    <header>
        <h1> DEEP Learning Excercise Website </h1>
        <div id="nav-menu">
          <a href="index.html">EA1 - ml5 Image Classification</a>
          <a href="ea2.html" class="current-main">EA2 - Regression </a>
          <a href="ea3.html">EA3 - Language Model mit RNN</a>
        </div>
        <div class="sub-menu">
            <div></div> <!-- Leerer Platzhalter für nicht ausgewählte Elemente -->
            <div id="nav-menu">
              <a href="ea2.html">Regression</a>
              <a href="documentation2.html">Documentation</a>
              <a href="results-discussion2.html" class="current">Results and Discussion</a>
            </div>
            <div></div> <!-- Leerer Platzhalter für nicht ausgewählte Elemente -->
        </div>
    </header>
    <main>
        <div id="white-area">
            <h2>1) Underfitting</h2>
            <p style="font-size:20px;">
                Bias (Verzerrung) ist der Fehler, der durch falsche Annahmen im Lernalgorithmus entsteht. Eine hohe Verzerrung kann einen Algorithmus dazu veranlassen, nicht die entsprechenden Beziehungen zwischen Eingabe und Ausgabe zu modellieren, was als Unteranpassung bezeichnet wird. Underfitting tritt auf, wenn ein Modell zu einfach ist und die zugrundeliegenden Muster in den Daten nicht erfasst. Ein unterangepasstes Modell berücksichtigt die Zusammenhänge bzw. “Signale” in den Daten nicht ausreichend. Es schafft es nicht, das Signal von dem Rauschen in den Daten zu trennen. Das führt dazu, dass weder die Daten noch die Realität genau genug beschrieben werden. Um ein Beispiel dafür zu erzeugen, habe ich ein einfachstes Modell (nur ein linear Layer) benutzt, dass der Komplexität der Ausgangsfunktion natürlich nicht gewachsen ist.
            </p>
            <p style="font-size:20px;">
                <img src="./pictures/underfitting.png" alt="Underfitting" style="max-height:2000px;">
            </p>

            <h2>2) Overfitting</h2>
            <p style="font-size:20px;">
                Overfitting tritt auf, wenn ein Modell zu komplex ist und das Rauschen in den Daten erfasst, was zu einer schlechten Generalisierungsleistung führt. Ein überangepasstes Modell orientiert sich zu sehr an den gesehenen Daten und reagiert mit einer höheren Fehlerrate bei neuen Beobachtungen. Es berücksichtigt unnötigerweise zu viel "Rauschen". Dafür verwende ich sehr lange trainierte Modelle mit vielen Layern und Parametern. Im ersten Bild ist die Überanpassung deutlich zu erkennen, einzelne Datencluster führen zu einer Funktion hohen Komplexitätsgrades. Im zweiten Bild ist ebenfalls eine Überanpassung zu erkennen, die vereinzelten Datenpunkte des Trainingssets werden hier fast perfekt erreicht. Beim Tenten auf dem Testdatensatz kommt es dann aber zu sehr großen Abweichungen.
            </p>
            <p style="font-size:20px;">
                <img src="./pictures/overfitting.png" alt="Overfitting" style="max-height:1000px;">
            </p>
            <p style="font-size:20px;">
                <img src="./pictures/overfitting2.png" alt="Overfitting 2" style="max-height:2000px;">
            </p>

            <h2>3) "perfect" fit</h2>
            <p style="font-size:20px;">
                Die Abwägung zwischen Underfitting und Overfitting: Das Modell ist komplex genug, um den Komplexitätsgrad der Funktion ziemlich gut nachbilden zu können, aber nicht zu komplex, um sich auf einzelne Abweichungen im Trainingsdatensatz zu fokussieren. Das Testen mit dem Testdatensatz fällt ähnlich gut aus wie das Testen auf dem Trainingsdatensatz, und beide Male sehr gut. Ich habe hier vor allem mit verschiedensten Kombinationen aus sigmoid-Layern Erfolg gefunden. Besonders gut funktioniert es auch mit nicht verrauschten Daten, je stärker verrauscht wird, desto weniger Erfolg hatte ich damit, eine geschwungene Form der Predictionskurve zu erhalten; meist wurde entstand eine lineare Funktion, die sich erst nach sehr sehr langem Training rechts etwas anhob und es meist innerhalb von 10000 Iterationen  nicht schaffte, sich auch links oder gar in der Mitte dem ursprünglichen Funktionsverlauf anzunähern. Das Modell beinhaltet drei sigmoid-Layer mit 8,4,3 Units und Bias und schließt mit einem softplus Layer mit einer Unit ab.
            </p>
            <p style="font-size:20px;">
                <img src="./pictures/perfectfit.png" alt="Perfect Fit" style="max-height:2000px;">
            </p>
        </div>
    </main>
  </body>
</html>